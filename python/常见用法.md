## requests用法
```py
# 安装python 依赖 requests
import requests

url = 'xxxx'
# 字典
params =  {
  "someKey": "junho"
}
datas = {
  "name": "junho"
}
headers = {
  "User-Agent": "Mozile..."
}
resp1 = requests.get(url=url, params= params, headers=headers)
resp2 = requests.get(url=url, headers=headers, datas=daras)
resp1.close()
resp2.close()
```

## 数据解析
1. re解析(正则)
```py
import re

reObj = re.compile(r"\d+")
str = "我的电话号码是：10 086，我"

lst = re.findall(reObj, str)

# 返回迭代器
lt = reObj.finditer(str)
for i in lt:
    print("迭代器", i.group())

print(lst)

resss = re.search(r"\d+", str)
print(resss.group())

# (?P<分组名字>正则) 通过 it.group("分组名称") .*? 代表字符号
```
# math从头匹配 match
```
2. bs4解析
基于HTML进行爬虫
```
import requests
from bs4 import BeautifulSoup

url = 'xxx'
resp = requests.get(url)
text = resp.text
resp.close()
page = BeautifulSoup(resp.text, "html.parser")
# page.find("table", class_="hq_table")
divs = page.find("div", attrs={"id": "bbs"})
ths = divs.find_all("th")
print(ths)
# for tr in trs:
  # print(tr)
    # div = tr.find_all("div")
    # print(table)
# print(trs)
```

3. xpath解析
解析XML内容
